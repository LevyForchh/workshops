---
title: "Distributions"
output:
  pdf_document: default
  html_document: default
---

# 1. Introduction

This is the R track of the *Distributions* workshop prepared by
Los Angeles County, ISAB.  Section numbering is intended to be
consistently referenced from the main workshop document available
at

<https://github.com/lacounty-isab/workshops/tree/master/distributions>

## 1.1. Preparation

Since R is oriented toward statistics, no special preparation is
required to work with distributions.
You can obtain a list of *baked-in* distributions by entering

```{r, eval=FALSE, echo=TRUE}
?Distributions
```

These are all part of the **stats** package which is available
in every R installation.

## 1.2 Conventions

R has a consistent naming convention for functions that work
with distributions - a single letter followed by the name of
the distribution.  The four single letters are

* `d` - density function
* `p` - percent point function (CDF)
* `q` - inverse of CDF
* `r` - random sampler

If we take the binomial distribution as an example, then
`dbinom` is a *binomial density function*.

```{r dbinom1}
dbinom(4, 10, 0.3)
```

This gives the probability of getting 4 successes after 10
attempts where each success has a probability of 0.3;
which is about `r round(dbinom(4,10,0.3), 3)*100` percent.

# 2 Discrete Distributions

## 2.1 Binomial Distribution

The binomial distribution has a `binom` suffix for each of
its standard methods.  We'll assume 100 trials with 20%
chance of success at each trial.  The value of the random
variable is the number of successes.
Let's start with the density function `dbinom`.
This is equation (7) of the math supplement.

$$
f_X(i) = \sum_{i=0}^n {n \choose i} p^i (1-p)^{n-i}
$$

Here we consider the case of $n=100$ and $p=0.2$.
We suspect that the highest probability will be around 20
successes since the probability of each success is 0.2 and
there are 100 trials.  The `dbinom` function accepts numeric
vectors, so we'll check `10`, `20`, and `30` in one go.

```{r dbinom2}
dbinom(c(10, 20, 30), 100, 0.2)
```

Sure enough, the density functon shows a 9.9% chance of
obtaining exactly 20 successes.  The probability for 10
and 30 are each less than 1%.

Now let's check the associated cumulative distribution
function, or CDF.  The CDF at a point is the cumulation
of probability from the density function for all points
equal or less.  Since we expect the average to be around
20, the CDF should be close to 0.5 at 20.

```{r dbinom3}
pbinom(c(10, 20, 30), 100, 0.2)
```

This shows that the probability of having *less than or equal
to 10 successes* is 0.57%.  The probability of having less
than or equal to 30 successes is 99.4%.

To better see the relationship between the density and 
cumulative distributions, we can plot them.

```{r binom_plot}
x <- seq(0, 100)
plot(x, pbinom(x, 100, 0.2), col="blue", pch=19)
points(x, dbinom(x, 100, 0.2), col="red", pch=19)
title(main="Binomial density and distribution for n=100, p=0.2")
```

**Quantiles** are the inverse of the CDF function.  For any
probability, a quantile function tells us the value of the
random variable for which the CDF is equal to that probability.

How many successes can we expect to have 25%, 50%, and 75%
of the time?

```{r bimon_quantiles}
qbinom(c(0.25, 0.5, 0.75), 100, 0.2)
```

The reason these come out to exact integers is because the
binomial random variable only takes integer values.  The
`qbinom` can be interpreted as *the smallest integer number
of successes with probability greater than or equal to the
argument*.  So it's not a strict inverse.

```{r binom_pbinom2}
pbinom(c(16, 17, 19, 20, 22, 23), 100, 0.2)
```

Sometimes it's useful to generate samples from a distribution.
In other words, the numbers are generated as if they came
from random variable values associated with outcomes of
the experiement.  The `rbinom` function is used for this.

```{r binom_rbinom}
b_sample <- rbinom(1000, 100, 0.2)
b_sample[1:100]
```

This simulates the arduous task of 

1. flipping an unfair coin (with 20% chance of heads) 100 times,
2. noting the number of heads,
3. repeating steps 1 and 2 for 1,000 times

It's fun to plot a histogram of our sample.  It should have a
shape "approaching" our density function.

```{r binom_hist}
hist(b_sample, breaks=30, xlim=c(0, 100), col="blue")
```

## 2.2 Poisson Distribution

The Poisson random variable represents the number of occurrences of an event
over a fixed interval of time.
This could be the number of crimes reported per hour.
The parameter of the random variable, usually
denoted by $\lambda$, turns out to be the expected number of occurrences.
The Poisson density function is given by

$$
f_X(i;\lambda) = e^{-\lambda} \frac{\lambda^i}{i!}
$$

For each $i$, this represents the probability of observing $i$ counts within
the unit time period.  R provides the usual four random variable functions
for the Poisson random variable.

* `dpois` - Poisson density (PMF) function
* `ppois` - Poisson probability (CDF) function
* `qpois` - Poisson quantile (inverse CDF) function
* `rpois` - Poisson random sample

Let's consider a case of a Poisson process where the expected
number of occurrences per time period is 5.

Since 5 is the expected value, we expect the mass function to be strong
near 5.  Let's check this.

```{r poisson_pmf1}
dpois(c(3,5,7), 5) * 100
```

We see a 14% of getting a 3 count, a 18% chance of getting a 5 count
and a 10% chance of getting a 7 count.  Now let's check the cumulative
distribution function.

```{r poisson_cdf1}
ppois(c(3,5,7), 5) * 100
```

The chance of getting

* 3 or less is 27%
* 5 or less is 62%
* 7 or less is 87%

Let's view this graphically.

```{r poisson_plot1}
x <- seq(0, 20)
plot(x, ppois(x, 5), col="blue", pch=19)
points(x, dpois(x, 5), col="red", pch=19)
title(main="Poisson density and distribution for lambda = 5")
```

The standard quantiles are giving by

```{r poisson_quantiles}
qpois(c(0.25, 0.5, 0.75), 5)
```

* 3 is the smallest count that occurs at least 25% of the time
* 5 is the smallest count that occurs at least 50% of the time
* 6 is the smallest count that occurs at least 75% of the time

Finally, let's run a Poisson simulation with 1,000 trials with
$\lambda = 5$.

```{r poisson_rpois}
poisson_sample <- rpois(1000, 5)
poisson_sample[1:100]
```

Let's check that our histogram looks anything like our PMF.

```{r poisson_hist}
hist(poisson_sample, breaks=20, xlim=c(0, 20), col="blue")
```


# 3 Continuous Distributions

## 3.1 Normal Distribution

The following functions address the normal distribution.

* `dnorm` - density function
* `pnorm` - cumulative distribution function
* `qnorm` - quantiles
* `rnorm` - random samples

```{r norm_pdf1}
dnorm(c(-3, -2, -1, 0, 1, 2, 3))
```

The symmetric character of the normal distribution is apparent 
here. We don't interpret these as probabilities (like we did 
with discrete mass function) since the continuous case represents
an infinitesimal range of the random variable. But we still extract
probabilities from the CDF.

```{r norm_cdf}
pnorm(c(-3, -2, -1, 0, 1, 2, 3)) * 100
```

Graphically the normal is the familiar bell curve.
```{r norm_plot}
x <- seq(-3, 3, by=0.02)
plot(x, pnorm(x), col='blue', type='l', lty='solid')
lines(x, dnorm(x), col='red')
title(main="Standard Normal PDF and CDF", ylab="", xlab="")
```

The `qnorm` function provides quantile information.
In other distributions we've shown quantile information for
quarters, i.e. quartile information.  But due to the role
of the normal distribution in the
[Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem),
we'll examine quantiles for 90%, 95%, and 97.5% since these are often
referenced in the study of confidence intervals.

```{r norm_quantile}
qnorm(c(0.5, 0.9, 0.95, 0.975))
```

Since the normal distribution is symmetric about the origin,
we expect half to lie on one side of 0 and half on the other
side.  The last number says that 97.5% of the curve lies to
the left of **1.96**.  This is a number we'll commit to memory
during the study of confidence intervals.

Finally, let's run a normal simulation with 1,000 trials 
using $\mu = 0$ and $\sigma = 1$.

```{r norm_sample}
norm_sample <- rnorm(1000)
round(norm_sample[1:100], 2)
```

Let's check that our histogram looks anything like our PMF.

```{r norm_hist}
hist(norm_sample, breaks=20, xlim=c(-4, 4), col="blue")
```


## 3.2 Exponential Distribution

The *exponential distribution* is a continuous distribution that
complements the discrete Poisson distribution that we encountered
above.  Whereas a Poisson random variable represents a count of
events that occur over a fixed unit of time, an exponential
random variable represents the amount of time between one such
event and the next.

The density function for the exponential function is

$$
f_X(x; \lambda) = \lambda e^{-\lambda x}
$$

where the expected wait time is $1/\lambda$  Let's go through
the usual moments with $\lambda = 1/3$.  The exponential function
decreases as x gets larger.

```{r exp_pdf}
x <- dexp(c(1,2,3,4), 1/3)
round(x, 2)
```

Since the expected wait time is $1/\lambda = 3$ units of time,
we expect the CDF to cross 50% there.

```{r exp_cdf}
x <- pexp(c(1,2,3,4), 1/3)
round(x, 2)
```

The is the PDF and CDF graphically.

```{r exp_plot}
x <- seq(0, 12, by=0.02)
plot(x, pexp(x, 1/3), col='blue', type='l', lty='solid')
lines(x, dexp(x, 1/3), col='red')
title(main="Exponential PDF and CDF", ylab="", xlab="")
```

Once again, we can see the relationship between the 
CDF $F_X(x; \lambda)$ and the PDF $f_X(x; \lambda)$.

$$
F_X(x; \lambda) = \int_0^x f_X(t; \lambda) dt
$$

The standard quartiles are given by

```{r exp_quartiles}
x = qexp(c(0.25, 0.5, 0.75), 1/3)
round(x, 2)
```

Notice that the median is 2.08.  This is an example the median
and the average do not agree, even for a continuous random variable.
These values tell us we should expect a wait time of

* 0.86 time units or less 25% of the time
* 2.08 time units or less 50% of the time
* 4.16 time units or less 75% of the time

Let's generate some exponential distributed time intervals for
a simulated Poisson process.

Finally, let's run an exponential simulation with 1,000 trials with
$\lambda = 1/3$.

```{r exp_rexp}
exp_sample <- rexp(1000, 1/3)
round(exp_sample[1:100], 2)
```

Let's check that our histogram looks anything like our PMF.

```{r exp_hist}
hist(exp_sample, breaks=24, xlim=c(0, 12), col="blue")
```

## Gamma Distribution

A Gamma random variable is often interpreted as a sum of $r$ independent
exponential random variables with the same parameter $\lambda$.  The
density function is

$$
f_X(x; \lambda, r) = \frac{\lambda}{\Gamma(r)}(\lambda x)^{r-1} e^{-\lambda x}
$$

So we have $r$ Poisson processes with an expected wait time of $1/\lambda$.
Let's continue using our Poisson process from before with an expected wait
time of 3 time units; but this time let's assume we are waiting for 5 of
them (one after another).  So in this particular case, $\lambda = 1/3$ and
$r = 5$.

The R functions related to the Gamma random variable take two parameters:

* `shape` - this corresponds to $r$ in the density function above
* `scale` - this corresponds to $\lambda$ in the density function above

Let's check a few density function values.

```{r gamma_pdf}
x <- dgamma(c(5, 10, 15, 20, 25), shape=5, scale=3)
round(x, 2)
```

The cumulative distribution function gives a better feel for the distribution.

```{r gamma_cdf}
x <- pgamma(c(5, 10, 15, 20, 25), shape=5, scale=3)
round(x, 2)
```

The is the PDF and CDF graphically.

```{r gamma_plot}
x <- seq(0, 50, by=0.02)
plot(x,  pgamma(x, shape=5, scale=3), col='blue', type='l', lty='solid')
lines(x, dgamma(x, shape=5, scale=3) * 10, col='red')
title(main="Gamma PDF and CDF", ylab=" ", xlab=" ")
```

The PDF was multiplied by 10 to emphasize its shape.
The quartiles are given by 

```{r gamma_quartile}
x <- qgamma(c(0.25, 0.5, 0.75), shape=5, scale=3)
round(x, 2)
```

This means that we can expect a trial (which consists of 5 independent Poisson
processes, each with expected duration of 3 time units) to take less than

* `r round(x[1], 2)` time units 25% of the time
* `r round(x[2], 2)` time units 50% of the time
* `r round(x[3], 2)` time units 75% of the time

Let's simulate 1,000 trials through a random number generator.

```{r gamma_sample}
g35_sample <- rgamma(1000, shape=5, scale=3)
round(g35_sample[1:100], 2)
```

Now let's check the histogram.

```{r gamma_hist}
hist(g35_sample, breaks=25, xlim=c(0, 50), col="blue")
```